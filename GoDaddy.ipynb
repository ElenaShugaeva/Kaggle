{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile, Path\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, RepeatedKFold\n",
    "import torch\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import Lasso, LinearRegression, Ridge, RidgeCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    " \n",
    "    batch_size = 64           \n",
    "    learning_rate= 0.00005  \n",
    "    weight_decay = 1e-6\n",
    "    architecture= \" \"     \n",
    "    epochs= 10\n",
    "    seed = 15\n",
    "    \n",
    "    if device == \"cuda\":\n",
    "        num_workers = 1\n",
    "        pin_memory = True\n",
    "    else:\n",
    "        num_workers = 0\n",
    "        pin_memory = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = config.seed\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "random_state= 15\n",
    "# os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['census_starter.csv', 'revealed_test.csv', 'sample_submission.csv', 'test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "with ZipFile('godaddy-microbusiness-density-forecasting.zip') as myzip:\n",
    "      print(myzip.namelist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 188 ms\n",
      "Wall time: 210 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with ZipFile('godaddy-microbusiness-density-forecasting.zip') as myzip:\n",
    "    data_train = myzip.open('train.csv')\n",
    "    data_test = myzip.open('test.csv')\n",
    "    data_census = myzip.open('census_starter.csv')\n",
    "    \n",
    "df_train = pd.read_csv(data_train)\n",
    "df_test = pd.read_csv(data_test)\n",
    "df_cen = pd.read_csv(data_census)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('godaddy-microbusiness-density-forecasting.zip') as myzip:\n",
    "    data_revealed_test = myzip.open('revealed_test.csv')\n",
    "df_revealed_test = pd.read_csv(data_revealed_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = df_train.copy()\n",
    "df_te = df_test.copy()\n",
    "df_ce = df_cen.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Explore the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>cfips</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>first_day_of_month</th>\n",
       "      <th>microbusiness_density</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_2019-08-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>3.007682</td>\n",
       "      <td>1249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001_2019-09-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2.884870</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001_2019-10-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>3.055843</td>\n",
       "      <td>1269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  cfips          county    state first_day_of_month  \\\n",
       "0  1001_2019-08-01   1001  Autauga County  Alabama         2019-08-01   \n",
       "1  1001_2019-09-01   1001  Autauga County  Alabama         2019-09-01   \n",
       "2  1001_2019-10-01   1001  Autauga County  Alabama         2019-10-01   \n",
       "\n",
       "   microbusiness_density  active  \n",
       "0               3.007682    1249  \n",
       "1               2.884870    1198  \n",
       "2               3.055843    1269  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122265 entries, 0 to 122264\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   row_id                 122265 non-null  object \n",
      " 1   cfips                  122265 non-null  int64  \n",
      " 2   county                 122265 non-null  object \n",
      " 3   state                  122265 non-null  object \n",
      " 4   first_day_of_month     122265 non-null  object \n",
      " 5   microbusiness_density  122265 non-null  float64\n",
      " 6   active                 122265 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-01\n",
      "2022-10-01\n",
      "2022-11-01\n"
     ]
    }
   ],
   "source": [
    "print(df_train['first_day_of_month'].min())\n",
    "print(df_train['first_day_of_month'].max())\n",
    "print(df_test['first_day_of_month'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_bb_2017</th>\n",
       "      <th>pct_bb_2018</th>\n",
       "      <th>pct_bb_2019</th>\n",
       "      <th>pct_bb_2020</th>\n",
       "      <th>pct_bb_2021</th>\n",
       "      <th>cfips</th>\n",
       "      <th>pct_college_2017</th>\n",
       "      <th>pct_college_2018</th>\n",
       "      <th>pct_college_2019</th>\n",
       "      <th>pct_college_2020</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_it_workers_2017</th>\n",
       "      <th>pct_it_workers_2018</th>\n",
       "      <th>pct_it_workers_2019</th>\n",
       "      <th>pct_it_workers_2020</th>\n",
       "      <th>pct_it_workers_2021</th>\n",
       "      <th>median_hh_inc_2017</th>\n",
       "      <th>median_hh_inc_2018</th>\n",
       "      <th>median_hh_inc_2019</th>\n",
       "      <th>median_hh_inc_2020</th>\n",
       "      <th>median_hh_inc_2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.6</td>\n",
       "      <td>78.9</td>\n",
       "      <td>80.6</td>\n",
       "      <td>82.7</td>\n",
       "      <td>85.5</td>\n",
       "      <td>1001</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>16.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>55317</td>\n",
       "      <td>58786.0</td>\n",
       "      <td>58731</td>\n",
       "      <td>57982.0</td>\n",
       "      <td>62660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74.5</td>\n",
       "      <td>78.1</td>\n",
       "      <td>81.8</td>\n",
       "      <td>85.1</td>\n",
       "      <td>87.9</td>\n",
       "      <td>1003</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>52562</td>\n",
       "      <td>55962.0</td>\n",
       "      <td>58320</td>\n",
       "      <td>61756.0</td>\n",
       "      <td>64346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.2</td>\n",
       "      <td>60.4</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.6</td>\n",
       "      <td>64.6</td>\n",
       "      <td>1005</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>33368</td>\n",
       "      <td>34186.0</td>\n",
       "      <td>32525</td>\n",
       "      <td>34990.0</td>\n",
       "      <td>36422.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pct_bb_2017  pct_bb_2018  pct_bb_2019  pct_bb_2020  pct_bb_2021  cfips  \\\n",
       "0         76.6         78.9         80.6         82.7         85.5   1001   \n",
       "1         74.5         78.1         81.8         85.1         87.9   1003   \n",
       "2         57.2         60.4         60.5         64.6         64.6   1005   \n",
       "\n",
       "   pct_college_2017  pct_college_2018  pct_college_2019  pct_college_2020  \\\n",
       "0              14.5              15.9              16.1              16.7   \n",
       "1              20.4              20.7              21.0              20.2   \n",
       "2               7.6               7.8               7.6               7.3   \n",
       "\n",
       "   ...  pct_it_workers_2017  pct_it_workers_2018  pct_it_workers_2019  \\\n",
       "0  ...                  1.3                  1.1                  0.7   \n",
       "1  ...                  1.4                  1.3                  1.4   \n",
       "2  ...                  0.5                  0.3                  0.8   \n",
       "\n",
       "   pct_it_workers_2020  pct_it_workers_2021  median_hh_inc_2017  \\\n",
       "0                  0.6                  1.1               55317   \n",
       "1                  1.0                  1.3               52562   \n",
       "2                  1.1                  0.8               33368   \n",
       "\n",
       "   median_hh_inc_2018  median_hh_inc_2019  median_hh_inc_2020  \\\n",
       "0             58786.0               58731             57982.0   \n",
       "1             55962.0               58320             61756.0   \n",
       "2             34186.0               32525             34990.0   \n",
       "\n",
       "   median_hh_inc_2021  \n",
       "0             62660.0  \n",
       "1             64346.0  \n",
       "2             36422.0  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cen.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3142 entries, 0 to 3141\n",
      "Data columns (total 26 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   pct_bb_2017            3142 non-null   float64\n",
      " 1   pct_bb_2018            3142 non-null   float64\n",
      " 2   pct_bb_2019            3142 non-null   float64\n",
      " 3   pct_bb_2020            3141 non-null   float64\n",
      " 4   pct_bb_2021            3141 non-null   float64\n",
      " 5   cfips                  3142 non-null   int64  \n",
      " 6   pct_college_2017       3142 non-null   float64\n",
      " 7   pct_college_2018       3142 non-null   float64\n",
      " 8   pct_college_2019       3142 non-null   float64\n",
      " 9   pct_college_2020       3141 non-null   float64\n",
      " 10  pct_college_2021       3141 non-null   float64\n",
      " 11  pct_foreign_born_2017  3142 non-null   float64\n",
      " 12  pct_foreign_born_2018  3142 non-null   float64\n",
      " 13  pct_foreign_born_2019  3142 non-null   float64\n",
      " 14  pct_foreign_born_2020  3141 non-null   float64\n",
      " 15  pct_foreign_born_2021  3141 non-null   float64\n",
      " 16  pct_it_workers_2017    3142 non-null   float64\n",
      " 17  pct_it_workers_2018    3141 non-null   float64\n",
      " 18  pct_it_workers_2019    3142 non-null   float64\n",
      " 19  pct_it_workers_2020    3141 non-null   float64\n",
      " 20  pct_it_workers_2021    3141 non-null   float64\n",
      " 21  median_hh_inc_2017     3142 non-null   int64  \n",
      " 22  median_hh_inc_2018     3141 non-null   float64\n",
      " 23  median_hh_inc_2019     3142 non-null   int64  \n",
      " 24  median_hh_inc_2020     3140 non-null   float64\n",
      " 25  median_hh_inc_2021     3140 non-null   float64\n",
      "dtypes: float64(23), int64(3)\n",
      "memory usage: 638.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_cen.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pct_bb_2020              1\n",
       "pct_bb_2021              1\n",
       "pct_college_2020         1\n",
       "pct_college_2021         1\n",
       "pct_foreign_born_2020    1\n",
       "pct_foreign_born_2021    1\n",
       "pct_it_workers_2018      1\n",
       "pct_it_workers_2020      1\n",
       "pct_it_workers_2021      1\n",
       "median_hh_inc_2018       1\n",
       "median_hh_inc_2020       2\n",
       "median_hh_inc_2021       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ce.isnull().sum().loc[(df_ce.isna().sum()!=0)].keys().tolist()\n",
    "df_cen.isna().sum().loc[(df_ce.isna().sum()!=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ce[\"pct_bb_2020\"] = df_ce[\"pct_bb_2020\"].fillna(df_ce[\"pct_bb_2019\"])\n",
    "df_ce[\"pct_bb_2021\"] = df_ce[\"pct_bb_2021\"].fillna(df_ce[\"pct_bb_2019\"])\n",
    "df_ce[\"pct_college_2020\"] = df_ce[\"pct_college_2020\"].fillna(df_ce[\"pct_college_2019\"])\n",
    "df_ce[\"pct_college_2021\"] = df_ce[\"pct_college_2021\"].fillna(df_ce[\"pct_college_2019\"])\n",
    "df_ce[\"pct_foreign_born_2020\"] = df_ce[\"pct_foreign_born_2020\"].fillna(df_ce[\"pct_foreign_born_2019\"])\n",
    "df_ce[\"pct_foreign_born_2021\"] = df_ce[\"pct_foreign_born_2021\"].fillna(df_ce[\"pct_foreign_born_2019\"])\n",
    "df_ce[\"pct_it_workers_2018\"] = df_ce[\"pct_it_workers_2018\"].fillna(df_ce[\"pct_it_workers_2017\"])\n",
    "df_ce[\"pct_it_workers_2020\"] = df_ce[\"pct_it_workers_2020\"].fillna(df_ce[\"pct_it_workers_2019\"])\n",
    "df_ce[\"pct_it_workers_2021\"] = df_ce[\"pct_it_workers_2021\"].fillna(df_ce[\"pct_it_workers_2019\"])\n",
    "df_ce[\"median_hh_inc_2018\"] = df_ce[\"median_hh_inc_2018\"].fillna(df_ce[\"median_hh_inc_2017\"])\n",
    "df_ce[\"median_hh_inc_2020\"] = df_ce[\"median_hh_inc_2020\"].fillna(df_ce[\"median_hh_inc_2019\"])\n",
    "df_ce[\"median_hh_inc_2021\"] = df_ce[\"median_hh_inc_2021\"].fillna(df_ce[\"median_hh_inc_2019\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ce.isnull().sum().loc[(df_ce.isna().sum()!=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. using 2-year shift betw. stat data and current factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train 2year shift между стат данными и текущим коэффициентом\n",
    "df_pct_bb = df_ce[['cfips','pct_bb_2018', 'pct_bb_2019', 'pct_bb_2020', 'pct_bb_2017']]\n",
    "df_pct_college = df_ce[['cfips', 'pct_college_2018', 'pct_college_2019', 'pct_college_2020', 'pct_college_2017']]\n",
    "df_pct_foreign_born = df_ce[['cfips', 'pct_foreign_born_2018', 'pct_foreign_born_2019', 'pct_foreign_born_2020', 'pct_foreign_born_2017']]\n",
    "df_pct_it_workers = df_ce[['cfips','pct_it_workers_2018', 'pct_it_workers_2019', 'pct_it_workers_2020', 'pct_it_workers_2017']]\n",
    "df_median_hh_inc = df_ce[['cfips','median_hh_inc_2018', 'median_hh_inc_2019', 'median_hh_inc_2020', 'median_hh_inc_2017']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test 2year shift между стат данными и текущим коэффициентом\n",
    "df_pct_bb_test = df_ce[['cfips', 'pct_bb_2020', 'pct_bb_2021']]\n",
    "df_pct_college_test = df_ce[['cfips', 'pct_college_2020', 'pct_college_2021']]\n",
    "df_pct_foreign_born_test = df_ce[['cfips', 'pct_foreign_born_2020', 'pct_foreign_born_2021']]\n",
    "df_pct_it_workers_test = df_ce[['cfips', 'pct_it_workers_2020', 'pct_it_workers_2021']]\n",
    "df_median_hh_inc_test = df_ce[['cfips','median_hh_inc_2020', 'median_hh_inc_2021']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct_bb_unpivoted = df_pct_bb.melt(id_vars=['cfips'], var_name='year', value_name='pct_bb')\n",
    "df_pct_college_unpivoted = df_pct_college.melt(id_vars=['cfips'], var_name='year', value_name='pct_college')\n",
    "df_pct_foreign_born_unpivoted = df_pct_foreign_born.melt(id_vars=['cfips'], var_name='year', value_name='pct_foreign_born')\n",
    "df_pct_it_workers_unpivoted = df_pct_it_workers.melt(id_vars=['cfips'], var_name='year', value_name='pct_it_workers')\n",
    "df_median_hh_inc_unpivoted = df_median_hh_inc.melt(id_vars=['cfips'], var_name='year', value_name='median_hh_inc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change reaserch year to +2 year(train)\n",
    "df_pct_bb_unpivoted[\"year\"]= df_pct_bb_unpivoted[\"year\"].str.extract('(\\d+)').astype('int')+2\n",
    "df_pct_college_unpivoted[\"year\"]= df_pct_college_unpivoted[\"year\"].str.extract('(\\d+)').astype('int')+2\n",
    "df_pct_foreign_born_unpivoted[\"year\"]= df_pct_foreign_born_unpivoted[\"year\"].str.extract('(\\d+)').astype('int')+2\n",
    "df_pct_it_workers_unpivoted[\"year\"]= df_pct_it_workers_unpivoted[\"year\"].str.extract('(\\d+)').astype('int')+2\n",
    "df_median_hh_inc_unpivoted[\"year\"]= df_median_hh_inc_unpivoted[\"year\"].str.extract('(\\d+)').astype('int')+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>cfips</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>first_day_of_month</th>\n",
       "      <th>microbusiness_density</th>\n",
       "      <th>active</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_2019-08-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>3.007682</td>\n",
       "      <td>1249</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001_2019-09-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2.884870</td>\n",
       "      <td>1198</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001_2019-10-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>3.055843</td>\n",
       "      <td>1269</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  cfips          county    state first_day_of_month  \\\n",
       "0  1001_2019-08-01   1001  Autauga County  Alabama         2019-08-01   \n",
       "1  1001_2019-09-01   1001  Autauga County  Alabama         2019-09-01   \n",
       "2  1001_2019-10-01   1001  Autauga County  Alabama         2019-10-01   \n",
       "\n",
       "   microbusiness_density  active  year  \n",
       "0               3.007682    1249  2019  \n",
       "1               2.884870    1198  2019  \n",
       "2               3.055843    1269  2019  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr['year'] = df_tr[\"first_day_of_month\"].str.extract('(\\d+)').astype('int')\n",
    "df_tr.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_1 = df_tr.merge(df_pct_bb_unpivoted, on=['cfips', 'year'], how = 'left')\n",
    "df_tr_2 = df_tr_1.merge(df_pct_college_unpivoted, on=['cfips', 'year'], how = 'left')\n",
    "df_tr_3 = df_tr_2.merge(df_pct_foreign_born_unpivoted, on=['cfips', 'year'], how = 'left')\n",
    "df_tr_4 = df_tr_3.merge(df_pct_it_workers_unpivoted, on=['cfips', 'year'], how = 'left')\n",
    "df_tr_5 = df_tr_4.merge(df_median_hh_inc_unpivoted, on=['cfips', 'year'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr_5.isnull().sum().loc[(df_tr_5.isna().sum()!=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct_bb_test_unpivoted = df_pct_bb_test.melt(id_vars=['cfips'], var_name='year', value_name='pct_bb')\n",
    "df_pct_college_test_unpivoted = df_pct_college_test.melt(id_vars=['cfips'], var_name='year', value_name='pct_college')\n",
    "df_pct_foreign_born_test_unpivoted = df_pct_foreign_born_test.melt(id_vars=['cfips'], var_name='year', value_name='pct_foreign_born')\n",
    "df_pct_it_workers_test_unpivoted = df_pct_it_workers_test.melt(id_vars=['cfips'], var_name='year', value_name='pct_it_workers')\n",
    "df_median_hh_inc_test_unpivoted = df_median_hh_inc_test.melt(id_vars=['cfips'], var_name='year', value_name='median_hh_inc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change reaserch year to +2 year(test)\n",
    "df_pct_bb_test_unpivoted[\"year\"]= df_pct_bb_test_unpivoted[\"year\"].str.extract('(\\d+)').astype('int')+2\n",
    "df_pct_college_test_unpivoted[\"year\"]= df_pct_college_test_unpivoted[\"year\"].str.extract('(\\d+)').astype('int')+2\n",
    "df_pct_foreign_born_test_unpivoted[\"year\"]= df_pct_foreign_born_test_unpivoted[\"year\"].str.extract('(\\d+)').astype('int')+2\n",
    "df_pct_it_workers_test_unpivoted[\"year\"]= df_pct_it_workers_test_unpivoted[\"year\"].str.extract('(\\d+)').astype('int')+2\n",
    "df_median_hh_inc_test_unpivoted[\"year\"]= df_median_hh_inc_test_unpivoted[\"year\"].str.extract('(\\d+)').astype('int')+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_te['year'] = df_te[\"first_day_of_month\"].str.extract('(\\d+)').astype('int')\n",
    "df_te_1 = df_te.merge(df_pct_bb_test_unpivoted, on=['cfips', 'year'], how = 'left')\n",
    "df_te_2 = df_te_1.merge(df_pct_college_test_unpivoted, on=['cfips', 'year'], how = 'left')\n",
    "df_te_3 = df_te_2.merge(df_pct_foreign_born_test_unpivoted, on=['cfips', 'year'], how = 'left')\n",
    "df_te_4 = df_te_3.merge(df_pct_it_workers_test_unpivoted, on=['cfips', 'year'], how = 'left')\n",
    "df_te_5 = df_te_4.merge(df_median_hh_inc_test_unpivoted, on=['cfips', 'year'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>cfips</th>\n",
       "      <th>first_day_of_month</th>\n",
       "      <th>year</th>\n",
       "      <th>pct_bb</th>\n",
       "      <th>pct_college</th>\n",
       "      <th>pct_foreign_born</th>\n",
       "      <th>pct_it_workers</th>\n",
       "      <th>median_hh_inc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_2022-11-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>2022</td>\n",
       "      <td>82.7</td>\n",
       "      <td>16.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>57982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003_2022-11-01</td>\n",
       "      <td>1003</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>2022</td>\n",
       "      <td>85.1</td>\n",
       "      <td>20.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61756.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005_2022-11-01</td>\n",
       "      <td>1005</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>2022</td>\n",
       "      <td>64.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>34990.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  cfips first_day_of_month  year  pct_bb  pct_college  \\\n",
       "0  1001_2022-11-01   1001         2022-11-01  2022    82.7         16.7   \n",
       "1  1003_2022-11-01   1003         2022-11-01  2022    85.1         20.2   \n",
       "2  1005_2022-11-01   1005         2022-11-01  2022    64.6          7.3   \n",
       "\n",
       "   pct_foreign_born  pct_it_workers  median_hh_inc  \n",
       "0               2.3             0.6        57982.0  \n",
       "1               3.4             1.0        61756.0  \n",
       "2               2.6             1.1        34990.0  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_te_5.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LinearRegression for prediction current stat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_bb = df_ce.loc[:,['pct_bb_2017','pct_bb_2018', 'pct_bb_2019', 'pct_bb_2020', 'pct_bb_2021' ]]\n",
    "pct_college = df_ce.loc[:,['pct_college_2017','pct_college_2018', 'pct_college_2019', 'pct_college_2020','pct_college_2021' ]]\n",
    "pct_foreign_born = df_ce.loc[:,[ 'pct_foreign_born_2017','pct_foreign_born_2018', 'pct_foreign_born_2019', 'pct_foreign_born_2020', 'pct_foreign_born_2021' ]]\n",
    "pct_it_workers = df_ce.loc[:,['pct_it_workers_2017','pct_it_workers_2018', 'pct_it_workers_2019', 'pct_it_workers_2020', 'pct_it_workers_2021' ]]\n",
    "median_hh_inc = df_ce.loc[:,['median_hh_inc_2017','median_hh_inc_2018', 'median_hh_inc_2019', 'median_hh_inc_2020', 'median_hh_inc_2021']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "X = pct_bb.loc[:,['pct_bb_2017','pct_bb_2018','pct_bb_2019','pct_bb_2020']]\n",
    "y = pct_bb.loc[:,['pct_bb_2021']]\n",
    "model.fit(X, y)\n",
    "X1 = pct_bb.loc[:,['pct_bb_2018','pct_bb_2019','pct_bb_2020','pct_bb_2021']]\n",
    "\n",
    "X.columns.tolist()\n",
    "X1.columns.tolist()\n",
    "dict(zip(X1.columns.tolist(),X.columns.tolist()))\n",
    "X1.rename(columns = dict(zip(X1.columns.tolist(),X.columns.tolist())), inplace = True)\n",
    "\n",
    "pct_bb['pct_bb_2022'] = np.round(model.predict(X1),1)\n",
    "X2 = pct_bb.loc[:,['pct_bb_2019','pct_bb_2020','pct_bb_2021', 'pct_bb_2022']]\n",
    "\n",
    "X2.columns.tolist()\n",
    "dict(zip(X2.columns.tolist(),X.columns.tolist()))\n",
    "X2.rename(columns = dict(zip(X2.columns.tolist(),X.columns.tolist())), inplace = True)\n",
    "\n",
    "pct_bb['pct_bb_2023'] = np.round(model.predict(X2),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pct_college.loc[:,['pct_college_2017','pct_college_2018','pct_college_2019','pct_college_2020']]\n",
    "y = pct_college.loc[:,['pct_college_2021']]\n",
    "model.fit(X, y)\n",
    "X1 = pct_college.loc[:,['pct_college_2018','pct_college_2019','pct_college_2020','pct_college_2021']]\n",
    "\n",
    "X.columns.tolist()\n",
    "X1.columns.tolist()\n",
    "dict(zip(X1.columns.tolist(),X.columns.tolist()))\n",
    "X1.rename(columns = dict(zip(X1.columns.tolist(),X.columns.tolist())), inplace = True)\n",
    "\n",
    "pct_college['pct_college_2022'] = np.round(model.predict(X1),1)\n",
    "X2 = pct_college.loc[:,['pct_college_2019','pct_college_2020','pct_college_2021', 'pct_college_2022']]\n",
    "\n",
    "X2.columns.tolist()\n",
    "dict(zip(X2.columns.tolist(),X.columns.tolist()))\n",
    "X2.rename(columns = dict(zip(X2.columns.tolist(),X.columns.tolist())), inplace = True)\n",
    "\n",
    "pct_college['pct_college_2023'] = np.round(model.predict(X2),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pct_foreign_born.loc[:,['pct_foreign_born_2017','pct_foreign_born_2018','pct_foreign_born_2019','pct_foreign_born_2020']]\n",
    "y = pct_foreign_born.loc[:,['pct_foreign_born_2021']]\n",
    "model.fit(X, y)\n",
    "X1 = pct_foreign_born.loc[:,['pct_foreign_born_2018','pct_foreign_born_2019','pct_foreign_born_2020','pct_foreign_born_2021']]\n",
    "\n",
    "X.columns.tolist()\n",
    "X1.columns.tolist()\n",
    "dict(zip(X1.columns.tolist(),X.columns.tolist()))\n",
    "X1.rename(columns = dict(zip(X1.columns.tolist(),X.columns.tolist())), inplace = True)\n",
    "\n",
    "pct_foreign_born['pct_foreign_born_2022'] = np.round(model.predict(X1),1)\n",
    "X2 = pct_foreign_born.loc[:,['pct_foreign_born_2019','pct_foreign_born_2020','pct_foreign_born_2021', 'pct_foreign_born_2022']]\n",
    "\n",
    "X2.columns.tolist()\n",
    "dict(zip(X2.columns.tolist(),X.columns.tolist()))\n",
    "X2.rename(columns = dict(zip(X2.columns.tolist(),X.columns.tolist())), inplace = True)\n",
    "\n",
    "pct_foreign_born['pct_foreign_born_2023'] = np.round(model.predict(X2),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pct_it_workers.loc[:,['pct_it_workers_2017','pct_it_workers_2018','pct_it_workers_2019','pct_it_workers_2020']]\n",
    "y = pct_it_workers.loc[:,['pct_it_workers_2021']]\n",
    "model.fit(X, y)\n",
    "X1 = pct_it_workers.loc[:,['pct_it_workers_2018','pct_it_workers_2019','pct_it_workers_2020','pct_it_workers_2021']]\n",
    "\n",
    "X.columns.tolist()\n",
    "X1.columns.tolist()\n",
    "dict(zip(X1.columns.tolist(),X.columns.tolist()))\n",
    "X1.rename(columns = dict(zip(X1.columns.tolist(),X.columns.tolist())), inplace = True)\n",
    "\n",
    "pct_it_workers['pct_it_workers_2022'] = np.round(model.predict(X1),1)\n",
    "X2 = pct_it_workers.loc[:,['pct_it_workers_2019','pct_it_workers_2020','pct_it_workers_2021', 'pct_it_workers_2022']]\n",
    "\n",
    "X2.columns.tolist()\n",
    "dict(zip(X2.columns.tolist(),X.columns.tolist()))\n",
    "X2.rename(columns = dict(zip(X2.columns.tolist(),X.columns.tolist())), inplace = True)\n",
    "\n",
    "pct_it_workers['pct_it_workers_2023'] = np.round(model.predict(X2),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = median_hh_inc.loc[:,['median_hh_inc_2017','median_hh_inc_2018','median_hh_inc_2019','median_hh_inc_2020']]\n",
    "y = median_hh_inc.loc[:,['median_hh_inc_2021']]\n",
    "model.fit(X, y)\n",
    "X1 = median_hh_inc.loc[:,['median_hh_inc_2018','median_hh_inc_2019','median_hh_inc_2020','median_hh_inc_2021']]\n",
    "\n",
    "X.columns.tolist()\n",
    "X1.columns.tolist()\n",
    "dict(zip(X1.columns.tolist(),X.columns.tolist()))\n",
    "X1.rename(columns = dict(zip(X1.columns.tolist(),X.columns.tolist())), inplace = True)\n",
    "\n",
    "median_hh_inc['median_hh_inc_2022'] = np.round(model.predict(X1),1)\n",
    "X2 = median_hh_inc.loc[:,['median_hh_inc_2019','median_hh_inc_2020','median_hh_inc_2021', 'median_hh_inc_2022']]\n",
    "\n",
    "X2.columns.tolist()\n",
    "dict(zip(X2.columns.tolist(),X.columns.tolist()))\n",
    "X2.rename(columns = dict(zip(X2.columns.tolist(),X.columns.tolist())), inplace = True)\n",
    "\n",
    "median_hh_inc['median_hh_inc_2023'] = np.round(model.predict(X2),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct_bb =pd.concat([pct_bb.loc[:,['pct_bb_2019', 'pct_bb_2020', 'pct_bb_2021', 'pct_bb_2022' ]], df_ce[['cfips']]], axis=1)\n",
    "df_pct_bb_test = pd.concat([pct_bb.loc[:,['pct_bb_2022', 'pct_bb_2023' ]] , df_ce[['cfips']]], axis=1)  \n",
    "df_pct_college = pd.concat([pct_college.loc[:,['pct_college_2019','pct_college_2020', 'pct_college_2021','pct_college_2022' ]],\n",
    "                             df_ce[['cfips']]], axis=1)\n",
    "df_pct_college_test = pd.concat([pct_college.loc[:,['pct_college_2022', 'pct_college_2023' ]], df_ce[['cfips']]], axis=1)     \n",
    "df_pct_foreign_born = pd.concat([pct_foreign_born.loc[:,['pct_foreign_born_2019','pct_foreign_born_2020', 'pct_foreign_born_2021',\n",
    "                                             'pct_foreign_born_2022' ]], df_ce[['cfips']]], axis=1)\n",
    "df_pct_foreign_born_test = pd.concat([pct_foreign_born.loc[:,['pct_foreign_born_2022', 'pct_foreign_born_2023' ]] ,\n",
    "                                       df_ce[['cfips']]], axis=1)\n",
    "df_pct_it_workers = pd.concat([pct_it_workers.loc[:,['pct_it_workers_2019','pct_it_workers_2020', 'pct_it_workers_2021',\n",
    "                                         'pct_it_workers_2022' ]],df_ce[['cfips']]], axis=1)\n",
    "df_pct_it_workers_test = pd.concat([pct_it_workers.loc[:,['pct_it_workers_2022', 'pct_it_workers_2023' ]] ,\n",
    "                                     df_ce[['cfips']]], axis=1)\n",
    "df_median_hh_inc = pd.concat([median_hh_inc.loc[:,['median_hh_inc_2019','median_hh_inc_2020', 'median_hh_inc_2021',\n",
    "                                                   'median_hh_inc_2022' ]], df_ce[['cfips']]], axis=1)\n",
    "df_median_hh_inc_test = pd.concat([median_hh_inc.loc[:,['median_hh_inc_2022', 'median_hh_inc_2023' ]] , df_ce[['cfips']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct_bb_unpivoted = df_pct_bb.melt(id_vars=['cfips'], var_name='year', value_name='pct_bb')\n",
    "df_pct_college_unpivoted = df_pct_college.melt(id_vars=['cfips'], var_name='year', value_name='pct_college')\n",
    "df_pct_foreign_born_unpivoted = df_pct_foreign_born.melt(id_vars=['cfips'], var_name='year', value_name='pct_foreign_born')\n",
    "df_pct_it_workers_unpivoted = df_pct_it_workers.melt(id_vars=['cfips'], var_name='year', value_name='pct_it_workers')\n",
    "df_median_hh_inc_unpivoted = df_median_hh_inc.melt(id_vars=['cfips'], var_name='year', value_name='median_hh_inc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct_bb_unpivoted[\"year\"]= df_pct_bb_unpivoted[\"year\"].str.extract('(\\d+)').astype('int')\n",
    "df_pct_college_unpivoted[\"year\"]= df_pct_college_unpivoted[\"year\"].str.extract('(\\d+)').astype('int')\n",
    "df_pct_foreign_born_unpivoted[\"year\"]= df_pct_foreign_born_unpivoted[\"year\"].str.extract('(\\d+)').astype('int')\n",
    "df_pct_it_workers_unpivoted[\"year\"]= df_pct_it_workers_unpivoted[\"year\"].str.extract('(\\d+)').astype('int')\n",
    "df_median_hh_inc_unpivoted[\"year\"]= df_median_hh_inc_unpivoted[\"year\"].str.extract('(\\d+)').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr['year'] = pd.to_datetime(df_tr[\"first_day_of_month\"]).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_1 = df_tr.merge(df_pct_bb_unpivoted, on=['cfips', 'year'], how = 'left')\n",
    "df_tr_2 = df_tr_1.merge(df_pct_college_unpivoted, on=['cfips', 'year'], how = 'left')\n",
    "df_tr_3 = df_tr_2.merge(df_pct_foreign_born_unpivoted, on=['cfips', 'year'], how = 'left')\n",
    "df_tr_4 = df_tr_3.merge(df_pct_it_workers_unpivoted, on=['cfips', 'year'], how = 'left')\n",
    "df_tr_5 = df_tr_4.merge(df_median_hh_inc_unpivoted, on=['cfips', 'year'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct_bb_test_unpivoted = df_pct_bb_test.melt(id_vars=['cfips'], var_name='year', value_name='pct_bb')\n",
    "df_pct_college_test_unpivoted = df_pct_college_test.melt(id_vars=['cfips'], var_name='year', value_name='pct_college')\n",
    "df_pct_foreign_born_test_unpivoted = df_pct_foreign_born_test.melt(id_vars=['cfips'], var_name='year', value_name='pct_foreign_born')\n",
    "df_pct_it_workers_test_unpivoted = df_pct_it_workers_test.melt(id_vars=['cfips'], var_name='year', value_name='pct_it_workers')\n",
    "df_median_hh_inc_test_unpivoted = df_median_hh_inc_test.melt(id_vars=['cfips'], var_name='year', value_name='median_hh_inc')\n",
    "df_pct_bb_test_unpivoted[\"year\"]= df_pct_bb_test_unpivoted[\"year\"].str.extract('(\\d+)').astype('int')\n",
    "df_pct_college_test_unpivoted[\"year\"]= df_pct_college_test_unpivoted[\"year\"].str.extract('(\\d+)').astype('int')\n",
    "df_pct_foreign_born_test_unpivoted[\"year\"]= df_pct_foreign_born_test_unpivoted[\"year\"].str.extract('(\\d+)').astype('int')\n",
    "df_pct_it_workers_test_unpivoted[\"year\"]= df_pct_it_workers_test_unpivoted[\"year\"].str.extract('(\\d+)').astype('int')\n",
    "df_median_hh_inc_test_unpivoted[\"year\"]= df_median_hh_inc_test_unpivoted[\"year\"].str.extract('(\\d+)').astype('int')\n",
    "df_te['year'] = pd.to_datetime(df_te[\"first_day_of_month\"]).dt.year\n",
    "df_te_1 = df_te.merge(df_pct_bb_test_unpivoted, on=['cfips', 'year'], how = 'left')\n",
    "df_te_2 = df_te_1.merge(df_pct_college_test_unpivoted, on=['cfips', 'year'], how = 'left')\n",
    "df_te_3 = df_te_2.merge(df_pct_foreign_born_test_unpivoted, on=['cfips', 'year'], how = 'left')\n",
    "df_te_4 = df_te_3.merge(df_pct_it_workers_test_unpivoted, on=['cfips', 'year'], how = 'left')\n",
    "df_te_5 = df_te_4.merge(df_median_hh_inc_test_unpivoted, on=['cfips', 'year'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month_sin(month):\n",
    "    theta = month * (2*np.pi / 12)\n",
    "    return np.sin(theta)\n",
    "def get_month_cos(month) :\n",
    "    theta = month * (2*np.pi / 12)\n",
    "    return np.cos(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"добавлены син-кос по месяцам, поскольку только они здесь цикличны\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df_tr_5.copy()\n",
    "df0test = df_te_5.copy()\n",
    "df0[\"first_day_of_month\"] = pd.to_datetime(df0[\"first_day_of_month\"])\n",
    "df0test[\"first_day_of_month\"] = pd.to_datetime(df0test[\"first_day_of_month\"])\n",
    "df0['month'] = df0[\"first_day_of_month\"].dt.month\n",
    "df0test['month'] = df0test[\"first_day_of_month\"].dt.month\n",
    "data_train0 = df0.loc[:,['cfips','year','month','pct_bb','pct_college','pct_foreign_born','pct_it_workers','median_hh_inc']]\n",
    "data_test0= df0test.loc[:,['cfips','year', 'month','pct_bb','pct_college','pct_foreign_born','pct_it_workers','median_hh_inc']]\n",
    "data_train0['sin_month'] = data_train0.month.map(get_month_sin(data_train0['month']))\n",
    "data_train0['cos_month'] = data_train0.month.map(get_month_cos(data_train0['month']))\n",
    "data_test0['sin_month'] = data_test0.month.map(get_month_sin(data_test0['month']))\n",
    "data_test0['cos_month'] = data_test0.month.map(get_month_cos(data_test0['month']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train0.copy()\n",
    "data_test = data_test0.copy()\n",
    "y_train= df0['microbusiness_density']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pct_college         0.481797\n",
       "median_hh_inc       0.388506\n",
       "pct_bb              0.344377\n",
       "pct_foreign_born    0.281323\n",
       "pct_it_workers      0.242714\n",
       "year                0.017025\n",
       "cfips               0.011767\n",
       "sin_month           0.003987\n",
       "month               0.002121\n",
       "cos_month           0.000910\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.corrwith(y_train).abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_69c6a_row0_col0, #T_69c6a_row1_col1, #T_69c6a_row2_col2, #T_69c6a_row3_col3, #T_69c6a_row4_col4, #T_69c6a_row5_col5, #T_69c6a_row6_col6, #T_69c6a_row7_col7, #T_69c6a_row8_col8, #T_69c6a_row9_col9 {\n",
       "  background-color: #0000ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row0_col1, #T_69c6a_row5_col1 {\n",
       "  background-color: #b6b6f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row0_col2, #T_69c6a_row0_col9, #T_69c6a_row5_col2, #T_69c6a_row5_col9 {\n",
       "  background-color: #8888f8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row0_col3 {\n",
       "  background-color: #d4d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row0_col4 {\n",
       "  background-color: #e1e1f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row0_col5, #T_69c6a_row1_col6, #T_69c6a_row2_col1, #T_69c6a_row2_col3, #T_69c6a_row2_col4, #T_69c6a_row2_col7, #T_69c6a_row2_col9, #T_69c6a_row6_col0, #T_69c6a_row9_col2, #T_69c6a_row9_col8 {\n",
       "  background-color: #f0f0f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row0_col6, #T_69c6a_row5_col0 {\n",
       "  background-color: #efeff3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row0_col7 {\n",
       "  background-color: #d7d7f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row0_col8, #T_69c6a_row5_col8, #T_69c6a_row6_col8 {\n",
       "  background-color: #e8e8f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row1_col0, #T_69c6a_row2_col0, #T_69c6a_row8_col0, #T_69c6a_row9_col0 {\n",
       "  background-color: #ececf3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row1_col2, #T_69c6a_row2_col8 {\n",
       "  background-color: #b4b4f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row1_col3, #T_69c6a_row6_col3 {\n",
       "  background-color: #a2a2f7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row1_col4, #T_69c6a_row3_col0, #T_69c6a_row8_col7 {\n",
       "  background-color: #e2e2f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row1_col5, #T_69c6a_row2_col5, #T_69c6a_row8_col4, #T_69c6a_row8_col5, #T_69c6a_row9_col5 {\n",
       "  background-color: #ededf3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row1_col7, #T_69c6a_row6_col1 {\n",
       "  background-color: #bcbcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row1_col8 {\n",
       "  background-color: #d8d8f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row1_col9 {\n",
       "  background-color: #5f5ffa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row2_col6 {\n",
       "  background-color: #e6e6f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row3_col1, #T_69c6a_row4_col9, #T_69c6a_row6_col2 {\n",
       "  background-color: #8686f8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row3_col2 {\n",
       "  background-color: #9494f7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row3_col4 {\n",
       "  background-color: #5959fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row3_col5 {\n",
       "  background-color: #a9a9f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row3_col6 {\n",
       "  background-color: #acacf6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row3_col7 {\n",
       "  background-color: #4242fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row3_col8, #T_69c6a_row7_col8 {\n",
       "  background-color: #e4e4f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row3_col9 {\n",
       "  background-color: #7c7cf9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row4_col0 {\n",
       "  background-color: #e0e0f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row4_col1 {\n",
       "  background-color: #adadf6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row4_col2 {\n",
       "  background-color: #8a8af8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row4_col3 {\n",
       "  background-color: #5252fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row4_col5, #T_69c6a_row5_col3, #T_69c6a_row5_col4 {\n",
       "  background-color: #9d9df7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row4_col6 {\n",
       "  background-color: #9797f7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row4_col7 {\n",
       "  background-color: #4343fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row4_col8 {\n",
       "  background-color: #e7e7f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row5_col6 {\n",
       "  background-color: #babaf6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row5_col7 {\n",
       "  background-color: #8c8cf8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row6_col4 {\n",
       "  background-color: #9a9af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row6_col5 {\n",
       "  background-color: #bdbdf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row6_col7 {\n",
       "  background-color: #a1a1f7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row6_col9 {\n",
       "  background-color: #8989f8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row7_col0 {\n",
       "  background-color: #dedef4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row7_col1 {\n",
       "  background-color: #9595f7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row7_col2 {\n",
       "  background-color: #8e8ef8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row7_col3 {\n",
       "  background-color: #4040fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row7_col4 {\n",
       "  background-color: #4646fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row7_col5 {\n",
       "  background-color: #9191f8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row7_col6 {\n",
       "  background-color: #a4a4f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row7_col9 {\n",
       "  background-color: #8181f8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row8_col1 {\n",
       "  background-color: #aaaaf6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row8_col2 {\n",
       "  background-color: #6a6afa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row8_col3 {\n",
       "  background-color: #d9d9f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row8_col6, #T_69c6a_row9_col4 {\n",
       "  background-color: #eaeaf3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row8_col9 {\n",
       "  background-color: #8d8df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row9_col1 {\n",
       "  background-color: #8080f8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_69c6a_row9_col3 {\n",
       "  background-color: #cacaf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row9_col6 {\n",
       "  background-color: #ebebf3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_69c6a_row9_col7 {\n",
       "  background-color: #dadaf4;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_69c6a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_69c6a_level0_col0\" class=\"col_heading level0 col0\" >cfips</th>\n",
       "      <th id=\"T_69c6a_level0_col1\" class=\"col_heading level0 col1\" >year</th>\n",
       "      <th id=\"T_69c6a_level0_col2\" class=\"col_heading level0 col2\" >month</th>\n",
       "      <th id=\"T_69c6a_level0_col3\" class=\"col_heading level0 col3\" >pct_bb</th>\n",
       "      <th id=\"T_69c6a_level0_col4\" class=\"col_heading level0 col4\" >pct_college</th>\n",
       "      <th id=\"T_69c6a_level0_col5\" class=\"col_heading level0 col5\" >pct_foreign_born</th>\n",
       "      <th id=\"T_69c6a_level0_col6\" class=\"col_heading level0 col6\" >pct_it_workers</th>\n",
       "      <th id=\"T_69c6a_level0_col7\" class=\"col_heading level0 col7\" >median_hh_inc</th>\n",
       "      <th id=\"T_69c6a_level0_col8\" class=\"col_heading level0 col8\" >sin_month</th>\n",
       "      <th id=\"T_69c6a_level0_col9\" class=\"col_heading level0 col9\" >cos_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_69c6a_level0_row0\" class=\"row_heading level0 row0\" >cfips</th>\n",
       "      <td id=\"T_69c6a_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_69c6a_row0_col1\" class=\"data row0 col1\" >-0.000000</td>\n",
       "      <td id=\"T_69c6a_row0_col2\" class=\"data row0 col2\" >-0.000000</td>\n",
       "      <td id=\"T_69c6a_row0_col3\" class=\"data row0 col3\" >0.038630</td>\n",
       "      <td id=\"T_69c6a_row0_col4\" class=\"data row0 col4\" >0.047669</td>\n",
       "      <td id=\"T_69c6a_row0_col5\" class=\"data row0 col5\" >-0.018601</td>\n",
       "      <td id=\"T_69c6a_row0_col6\" class=\"data row0 col6\" >-0.023915</td>\n",
       "      <td id=\"T_69c6a_row0_col7\" class=\"data row0 col7\" >0.059222</td>\n",
       "      <td id=\"T_69c6a_row0_col8\" class=\"data row0 col8\" >0.000000</td>\n",
       "      <td id=\"T_69c6a_row0_col9\" class=\"data row0 col9\" >-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69c6a_level0_row1\" class=\"row_heading level0 row1\" >year</th>\n",
       "      <td id=\"T_69c6a_row1_col0\" class=\"data row1 col0\" >-0.000000</td>\n",
       "      <td id=\"T_69c6a_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_69c6a_row1_col2\" class=\"data row1 col2\" >-0.325776</td>\n",
       "      <td id=\"T_69c6a_row1_col3\" class=\"data row1 col3\" >0.262968</td>\n",
       "      <td id=\"T_69c6a_row1_col4\" class=\"data row1 col4\" >0.046045</td>\n",
       "      <td id=\"T_69c6a_row1_col5\" class=\"data row1 col5\" >-0.001370</td>\n",
       "      <td id=\"T_69c6a_row1_col6\" class=\"data row1 col6\" >-0.034109</td>\n",
       "      <td id=\"T_69c6a_row1_col7\" class=\"data row1 col7\" >0.180103</td>\n",
       "      <td id=\"T_69c6a_row1_col8\" class=\"data row1 col8\" >0.066297</td>\n",
       "      <td id=\"T_69c6a_row1_col9\" class=\"data row1 col9\" >0.293768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69c6a_level0_row2\" class=\"row_heading level0 row2\" >month</th>\n",
       "      <td id=\"T_69c6a_row2_col0\" class=\"data row2 col0\" >-0.000000</td>\n",
       "      <td id=\"T_69c6a_row2_col1\" class=\"data row2 col1\" >-0.325776</td>\n",
       "      <td id=\"T_69c6a_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_69c6a_row2_col3\" class=\"data row2 col3\" >-0.093470</td>\n",
       "      <td id=\"T_69c6a_row2_col4\" class=\"data row2 col4\" >-0.016481</td>\n",
       "      <td id=\"T_69c6a_row2_col5\" class=\"data row2 col5\" >0.000601</td>\n",
       "      <td id=\"T_69c6a_row2_col6\" class=\"data row2 col6\" >0.010756</td>\n",
       "      <td id=\"T_69c6a_row2_col7\" class=\"data row2 col7\" >-0.052976</td>\n",
       "      <td id=\"T_69c6a_row2_col8\" class=\"data row2 col8\" >0.220083</td>\n",
       "      <td id=\"T_69c6a_row2_col9\" class=\"data row2 col9\" >-0.775172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69c6a_level0_row3\" class=\"row_heading level0 row3\" >pct_bb</th>\n",
       "      <td id=\"T_69c6a_row3_col0\" class=\"data row3 col0\" >0.038630</td>\n",
       "      <td id=\"T_69c6a_row3_col1\" class=\"data row3 col1\" >0.262968</td>\n",
       "      <td id=\"T_69c6a_row3_col2\" class=\"data row3 col2\" >-0.093470</td>\n",
       "      <td id=\"T_69c6a_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_69c6a_row3_col4\" class=\"data row3 col4\" >0.625913</td>\n",
       "      <td id=\"T_69c6a_row3_col5\" class=\"data row3 col5\" >0.286659</td>\n",
       "      <td id=\"T_69c6a_row3_col6\" class=\"data row3 col6\" >0.264236</td>\n",
       "      <td id=\"T_69c6a_row3_col7\" class=\"data row3 col7\" >0.708522</td>\n",
       "      <td id=\"T_69c6a_row3_col8\" class=\"data row3 col8\" >0.016072</td>\n",
       "      <td id=\"T_69c6a_row3_col9\" class=\"data row3 col9\" >0.085904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69c6a_level0_row4\" class=\"row_heading level0 row4\" >pct_college</th>\n",
       "      <td id=\"T_69c6a_row4_col0\" class=\"data row4 col0\" >0.047669</td>\n",
       "      <td id=\"T_69c6a_row4_col1\" class=\"data row4 col1\" >0.046045</td>\n",
       "      <td id=\"T_69c6a_row4_col2\" class=\"data row4 col2\" >-0.016481</td>\n",
       "      <td id=\"T_69c6a_row4_col3\" class=\"data row4 col3\" >0.625913</td>\n",
       "      <td id=\"T_69c6a_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_69c6a_row4_col5\" class=\"data row4 col5\" >0.333935</td>\n",
       "      <td id=\"T_69c6a_row4_col6\" class=\"data row4 col6\" >0.350307</td>\n",
       "      <td id=\"T_69c6a_row4_col7\" class=\"data row4 col7\" >0.706099</td>\n",
       "      <td id=\"T_69c6a_row4_col8\" class=\"data row4 col8\" >0.002894</td>\n",
       "      <td id=\"T_69c6a_row4_col9\" class=\"data row4 col9\" >0.015114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69c6a_level0_row5\" class=\"row_heading level0 row5\" >pct_foreign_born</th>\n",
       "      <td id=\"T_69c6a_row5_col0\" class=\"data row5 col0\" >-0.018601</td>\n",
       "      <td id=\"T_69c6a_row5_col1\" class=\"data row5 col1\" >-0.001370</td>\n",
       "      <td id=\"T_69c6a_row5_col2\" class=\"data row5 col2\" >0.000601</td>\n",
       "      <td id=\"T_69c6a_row5_col3\" class=\"data row5 col3\" >0.286659</td>\n",
       "      <td id=\"T_69c6a_row5_col4\" class=\"data row5 col4\" >0.333935</td>\n",
       "      <td id=\"T_69c6a_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "      <td id=\"T_69c6a_row5_col6\" class=\"data row5 col6\" >0.200818</td>\n",
       "      <td id=\"T_69c6a_row5_col7\" class=\"data row5 col7\" >0.386780</td>\n",
       "      <td id=\"T_69c6a_row5_col8\" class=\"data row5 col8\" >-0.000069</td>\n",
       "      <td id=\"T_69c6a_row5_col9\" class=\"data row5 col9\" >-0.000571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69c6a_level0_row6\" class=\"row_heading level0 row6\" >pct_it_workers</th>\n",
       "      <td id=\"T_69c6a_row6_col0\" class=\"data row6 col0\" >-0.023915</td>\n",
       "      <td id=\"T_69c6a_row6_col1\" class=\"data row6 col1\" >-0.034109</td>\n",
       "      <td id=\"T_69c6a_row6_col2\" class=\"data row6 col2\" >0.010756</td>\n",
       "      <td id=\"T_69c6a_row6_col3\" class=\"data row6 col3\" >0.264236</td>\n",
       "      <td id=\"T_69c6a_row6_col4\" class=\"data row6 col4\" >0.350307</td>\n",
       "      <td id=\"T_69c6a_row6_col5\" class=\"data row6 col5\" >0.200818</td>\n",
       "      <td id=\"T_69c6a_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "      <td id=\"T_69c6a_row6_col7\" class=\"data row6 col7\" >0.294490</td>\n",
       "      <td id=\"T_69c6a_row6_col8\" class=\"data row6 col8\" >-0.002242</td>\n",
       "      <td id=\"T_69c6a_row6_col9\" class=\"data row6 col9\" >-0.009670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69c6a_level0_row7\" class=\"row_heading level0 row7\" >median_hh_inc</th>\n",
       "      <td id=\"T_69c6a_row7_col0\" class=\"data row7 col0\" >0.059222</td>\n",
       "      <td id=\"T_69c6a_row7_col1\" class=\"data row7 col1\" >0.180103</td>\n",
       "      <td id=\"T_69c6a_row7_col2\" class=\"data row7 col2\" >-0.052976</td>\n",
       "      <td id=\"T_69c6a_row7_col3\" class=\"data row7 col3\" >0.708522</td>\n",
       "      <td id=\"T_69c6a_row7_col4\" class=\"data row7 col4\" >0.706099</td>\n",
       "      <td id=\"T_69c6a_row7_col5\" class=\"data row7 col5\" >0.386780</td>\n",
       "      <td id=\"T_69c6a_row7_col6\" class=\"data row7 col6\" >0.294490</td>\n",
       "      <td id=\"T_69c6a_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "      <td id=\"T_69c6a_row7_col8\" class=\"data row7 col8\" >0.012732</td>\n",
       "      <td id=\"T_69c6a_row7_col9\" class=\"data row7 col9\" >0.046701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69c6a_level0_row8\" class=\"row_heading level0 row8\" >sin_month</th>\n",
       "      <td id=\"T_69c6a_row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
       "      <td id=\"T_69c6a_row8_col1\" class=\"data row8 col1\" >0.066297</td>\n",
       "      <td id=\"T_69c6a_row8_col2\" class=\"data row8 col2\" >0.220083</td>\n",
       "      <td id=\"T_69c6a_row8_col3\" class=\"data row8 col3\" >0.016072</td>\n",
       "      <td id=\"T_69c6a_row8_col4\" class=\"data row8 col4\" >0.002894</td>\n",
       "      <td id=\"T_69c6a_row8_col5\" class=\"data row8 col5\" >-0.000069</td>\n",
       "      <td id=\"T_69c6a_row8_col6\" class=\"data row8 col6\" >-0.002242</td>\n",
       "      <td id=\"T_69c6a_row8_col7\" class=\"data row8 col7\" >0.012732</td>\n",
       "      <td id=\"T_69c6a_row8_col8\" class=\"data row8 col8\" >1.000000</td>\n",
       "      <td id=\"T_69c6a_row8_col9\" class=\"data row8 col9\" >-0.040371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69c6a_level0_row9\" class=\"row_heading level0 row9\" >cos_month</th>\n",
       "      <td id=\"T_69c6a_row9_col0\" class=\"data row9 col0\" >-0.000000</td>\n",
       "      <td id=\"T_69c6a_row9_col1\" class=\"data row9 col1\" >0.293768</td>\n",
       "      <td id=\"T_69c6a_row9_col2\" class=\"data row9 col2\" >-0.775172</td>\n",
       "      <td id=\"T_69c6a_row9_col3\" class=\"data row9 col3\" >0.085904</td>\n",
       "      <td id=\"T_69c6a_row9_col4\" class=\"data row9 col4\" >0.015114</td>\n",
       "      <td id=\"T_69c6a_row9_col5\" class=\"data row9 col5\" >-0.000571</td>\n",
       "      <td id=\"T_69c6a_row9_col6\" class=\"data row9 col6\" >-0.009670</td>\n",
       "      <td id=\"T_69c6a_row9_col7\" class=\"data row9 col7\" >0.046701</td>\n",
       "      <td id=\"T_69c6a_row9_col8\" class=\"data row9 col8\" >-0.040371</td>\n",
       "      <td id=\"T_69c6a_row9_col9\" class=\"data row9 col9\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2097816e640>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.corr().style.background_gradient(sns.light_palette('blue', as_cmap=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfips: 0.9410602924974806\n",
      "year: 0.0\n",
      "month: 0.9585320860220025\n",
      "pct_bb: 3.5574912153603106e-13\n",
      "pct_college: 3.7198405795953476e-17\n",
      "pct_foreign_born: 4.3624307029862637e-13\n",
      "pct_it_workers: 1.5127871029105457e-23\n",
      "median_hh_inc: 8.408018136174087e-13\n",
      "sin_month: 0.0\n",
      "cos_month: 0.0\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "for name, values in data_train.items():\n",
    "    st = adfuller(values[:10000])[1]\n",
    "    print(f'{name}: {st}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(A, F):\n",
    "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StandardScaler()\n",
    "train_ssc = ssc.fit_transform(data_train)\n",
    "target = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6.61 s\n",
      "Wall time: 1min 39s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10, estimator=LGBMRegressor(random_state=15), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        &#x27;max_depth&#x27;: [3, 6, 8, 10, 12, 15, 20],\n",
       "                                        &#x27;min_child_samples&#x27;: [5, 10, 15],\n",
       "                                        &#x27;num_leaves&#x27;: [20, 40, 60, 80, 100],\n",
       "                                        &#x27;reg_alpha&#x27;: [0.0, 0.1, 0.2, 0.3, 0.4]},\n",
       "                   random_state=15, return_train_score=True,\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10, estimator=LGBMRegressor(random_state=15), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        &#x27;max_depth&#x27;: [3, 6, 8, 10, 12, 15, 20],\n",
       "                                        &#x27;min_child_samples&#x27;: [5, 10, 15],\n",
       "                                        &#x27;num_leaves&#x27;: [20, 40, 60, 80, 100],\n",
       "                                        &#x27;reg_alpha&#x27;: [0.0, 0.1, 0.2, 0.3, 0.4]},\n",
       "                   random_state=15, return_train_score=True,\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(random_state=15)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(random_state=15)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=LGBMRegressor(random_state=15), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        'max_depth': [3, 6, 8, 10, 12, 15, 20],\n",
       "                                        'min_child_samples': [5, 10, 15],\n",
       "                                        'num_leaves': [20, 40, 60, 80, 100],\n",
       "                                        'reg_alpha': [0.0, 0.1, 0.2, 0.3, 0.4]},\n",
       "                   random_state=15, return_train_score=True,\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "features = data_train\n",
    "\n",
    "RS_lgb = RandomizedSearchCV(\n",
    "            estimator=lgb.LGBMRegressor(random_state=random_state) ,   #n_estimators=5000 next add      \n",
    "            param_distributions = {                \n",
    "              'num_leaves':[20,40,60,80,100], \n",
    "              'min_child_samples':[5,10,15],\n",
    "              'max_depth':[3,  6, 8, 10, 12, 15, 20],\n",
    "              'learning_rate':[0.05,0.10,0.15,0.20,0.25,0.30],\n",
    "              'reg_alpha':[0.0, 0.1, 0.2 , 0.3, 0.4]\n",
    "            },\n",
    "            scoring = 'neg_mean_absolute_error',    \n",
    "            cv = 10,                                \n",
    "            n_jobs = -1,                           \n",
    "            random_state=random_state ,\n",
    "            return_train_score=True,\n",
    "            n_iter=20,                             \n",
    "            verbose =0     )\n",
    "\n",
    "RS_lgb.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best_params:\n",
      "{'reg_alpha': 0.3, 'num_leaves': 80, 'min_child_samples': 15, 'max_depth': 6, 'learning_rate': 0.05}\n",
      " The best MAE_cv score: 1.771358570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30.356112352313755"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The best_params:\\n{}\\n\".format(RS_lgb.best_params_), \n",
    "        \"The best MAE_cv score: {:.9f}\".format(-RS_lgb.best_score_))\n",
    "\n",
    "smape(target, RS_lgb.predict(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "The best_params:\n",
      "{'min_child_weight': 3, 'max_depth': 4, 'learning_rate': 0.05, 'gamma': 0.4, 'colsample_bytree': 0.5}\n",
      " The best MSE_cv score: 1.648596263\n",
      "CPU times: total: 14.8 s\n",
      "Wall time: 1min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33.713199375673106"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "features = data_train\n",
    "\n",
    "RS_xgb = RandomizedSearchCV(\n",
    "            estimator=XGBRegressor( verbosity=0, random_state=random_state) ,         \n",
    "            param_distributions = {                \n",
    "            'learning_rate' : [0.05,0.10,0.15,0.20,0.25,0.30],\n",
    "             'max_depth' : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "             'min_child_weight' : [ 1, 3, 5, 7 ],\n",
    "             'gamma': [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "             'colsample_bytree' : [ 0.3, 0.4, 0.5 , 0.7,1 ]\n",
    "            },\n",
    "            scoring = 'neg_mean_absolute_error',    \n",
    "            cv = 5,                                 \n",
    "            n_jobs = -1,                           \n",
    "            random_state=random_state ,\n",
    "            return_train_score=True,\n",
    "            n_iter=5,                          \n",
    "            verbose =5     )\n",
    "\n",
    "RS_xgb.fit(features, target)\n",
    "print(\"The best_params:\\n{}\\n\".format(RS_xgb.best_params_), \n",
    "        \"The best MAE_cv score: {:.9f}\".format(-RS_xgb.best_score_))\n",
    "\n",
    "smape(target, RS_xgb.predict(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N_estimators here, MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test CV_score for LGBM baseline: MSE_test : 31.212644169\n",
      "CPU times: total: 4min 43s\n",
      "Wall time: 2min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.322658543385707"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipe_lgb = Pipeline([\n",
    "    ('scaler', None),\n",
    "    ('regressor', lgb.LGBMRegressor( reg_alpha= 0.3, num_leaves= 80, min_child_samples= 15, max_depth= 6,\n",
    "                                    learning_rate= 0.05,random_state=random_state, n_estimators=5000))])\n",
    "features = data_train\n",
    "pipe_lgb.fit(features, target)\n",
    "predict_lgb = pipe_lgb.predict(features)\n",
    "\n",
    "scores = cross_val_score(pipe_lgb, features, target.values.ravel(), scoring= 'neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "\n",
    "print('Test CV_score for LGBM baseline: MSE_test', f\": {-np.mean(scores):.9f}\")\n",
    "forecast= predict_lgb\n",
    "actual = target\n",
    "smape(actual, forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test CV_score for XGB baseline: MSE_test : 22.652678887\n",
      "CPU times: total: 11min 32s\n",
      "Wall time: 5min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.275507430742735"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipe_xgb = Pipeline([  \n",
    "    ('scaler', None),\n",
    "    ('regressor', XGBRegressor(gamma= 0.4, colsample_bytree= 0.5, min_child_weight = 3, max_depth= 4,\n",
    "                                learning_rate= 0.05,random_state=random_state, n_estimators=5000,\n",
    "                                verbosity = 0))])\n",
    "features = data_train\n",
    "\n",
    "pipe_xgb.fit(features, target)\n",
    "predict_xgb = pipe_xgb.predict(features)\n",
    "\n",
    "scores = cross_val_score(pipe_xgb, features, target.values.ravel(), scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "\n",
    "print('Test CV_score for XGB baseline: MSE_test', f\": {-np.mean(scores):.9f}\")\n",
    "forecast= predict_xgb\n",
    "actual = target\n",
    "smape(actual, forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test CV_score for LR baseline: MAE_test : 1.72217\n",
      "SMAPE_score for LR baseline :44.90011\n"
     ]
    }
   ],
   "source": [
    "features = train_ssc\n",
    "LR = LinearRegression()\n",
    "LR.fit(features, target)\n",
    "scores = cross_val_score(LR, features, target.values.ravel(), scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "print('Test CV_score for LR baseline: MAE_test', f\": {-np.mean(scores):.5f}\")\n",
    "print('SMAPE_score for LR baseline', f\":{smape(target, LR.predict(features)):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test CV_score for poly_LR baseline: MAE_test : 1.574352782\n",
      "SMAPE_score for poly_LR baseline :37.40494\n",
      "CPU times: total: 1.92 s\n",
      "Wall time: 2.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "features = train_ssc\n",
    "pipe_poly_LR = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('regressor', LinearRegression())])\n",
    "pipe_poly_LR.fit(features, target)\n",
    "\n",
    "scores = cross_val_score(pipe_poly_LR, features, target.values.ravel(), scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "print('Test CV_score for poly_LR baseline: MAE_test', f\": {-np.mean(scores):.9f}\")\n",
    "print('SMAPE_score for poly_LR baseline', f\":{smape(target, pipe_poly_LR.predict(features)):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV_score for poly_ridgeCV baseline: MAE : 1.44810\n",
      "SMAPE_score for poly_ridgeCV baseline :37.40221\n",
      "CPU times: total: 8.05 s\n",
      "Wall time: 6.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = train_ssc\n",
    "cv = RepeatedKFold(n_splits= 10 , n_repeats= 3 , random_state= random_state )\n",
    "\n",
    "pipe_poly_RidgeCV = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('regressor', RidgeCV(alphas= (0.05, 50.0), cv=cv, scoring='neg_mean_absolute_error'))])\n",
    "pipe_poly_RidgeCV.fit(features, target)\n",
    "\n",
    "print('Best CV_score for poly_ridgeCV baseline: MAE', f\": {-pipe_poly_RidgeCV.named_steps['regressor'].best_score_:.5f}\")\n",
    "print('SMAPE_score for poly_ridgeCV baseline', f\":{smape(target, pipe_poly_RidgeCV.predict(features)):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('godaddy-microbusiness-density-forecasting.zip') as myzip:\n",
    "    data_sub = myzip.open('sample_submission.csv')\n",
    "     \n",
    "df_sub = pd.read_csv(data_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_id', 'microbusiness_density'], dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>microbusiness_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_2022-11-01</td>\n",
       "      <td>3.817671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003_2022-11-01</td>\n",
       "      <td>3.817671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005_2022-11-01</td>\n",
       "      <td>3.817671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  microbusiness_density\n",
       "0  1001_2022-11-01               3.817671\n",
       "1  1003_2022-11-01               3.817671\n",
       "2  1005_2022-11-01               3.817671"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"pipe_lgb\"\"\"\n",
    "y_test_predict_lgb = pipe_lgb.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>microbusiness_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_2022-11-01</td>\n",
       "      <td>3.385132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003_2022-11-01</td>\n",
       "      <td>8.466618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005_2022-11-01</td>\n",
       "      <td>1.277283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007_2022-11-01</td>\n",
       "      <td>1.279167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009_2022-11-01</td>\n",
       "      <td>1.798717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  microbusiness_density\n",
       "0  1001_2022-11-01               3.385132\n",
       "1  1003_2022-11-01               8.466618\n",
       "2  1005_2022-11-01               1.277283\n",
       "3  1007_2022-11-01               1.279167\n",
       "4  1009_2022-11-01               1.798717"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Id = df_test['row_id']\n",
    "submission = pd.DataFrame({'row_id': test_Id,'microbusiness_density': y_test_predict_lgb})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>microbusiness_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25080.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.024496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.640430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-6.896722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.897635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.828457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.895719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>145.443796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       microbusiness_density\n",
       "count           25080.000000\n",
       "mean                4.024496\n",
       "std                 4.640430\n",
       "min                -6.896722\n",
       "25%                 1.897635\n",
       "50%                 2.828457\n",
       "75%                 4.895719\n",
       "max               145.443796"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newArr = y_test_predict_lgb[y_test_predict_lgb < 0]\n",
    "len(newArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25080"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_array = y_test_predict_lgb\n",
    "my_array[my_array < 0] = 0.000000\n",
    "len(my_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>microbusiness_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25080.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.028762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.635234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.897635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.828457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.895719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>145.443796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       microbusiness_density\n",
       "count           25080.000000\n",
       "mean                4.028762\n",
       "std                 4.635234\n",
       "min                 0.000000\n",
       "25%                 1.897635\n",
       "50%                 2.828457\n",
       "75%                 4.895719\n",
       "max               145.443796"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Id = df_test['row_id']\n",
    "submission = pd.DataFrame({'row_id': test_Id,'microbusiness_density': my_array})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "score = make_scorer(smape, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повтор с данной оценкой даcт submission 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preparing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(data_train, y_train, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= df0['microbusiness_density']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ssc = ssc.fit_transform(X_tr)\n",
    "X_val_ssc = ssc.transform(X_val)\n",
    "X_test_ssc = ssc.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "msc = MinMaxScaler()\n",
    "y_train_msc = msc.fit_transform(y_tr.to_numpy().reshape(-1, 1)) #mm for DF not pd.series [y_train]\n",
    "y_val_msc = msc.transform(y_val.to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = torch.Tensor(X_train_ssc)\n",
    "train_targets = torch.Tensor(y_train_msc)\n",
    "\n",
    "val_features = torch.Tensor(X_val_ssc)\n",
    "val_targets = torch.Tensor(y_val_msc)\n",
    "\n",
    "test_features = torch.Tensor(X_test_ssc)\n",
    "\n",
    "train_ds = TensorDataset(train_features, train_targets)\n",
    "val_ds = TensorDataset(val_features, val_targets)\n",
    "train_loader = DataLoader(train_ds, batch_size=config.batch_size, shuffle=False, drop_last=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=config.batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Образец https://towardsdatascience.com/building-rnn-lstm-and-gru-for-time-series-using-pytorch-a46e5b094e7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout_prob):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout_prob)   \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)                                                      \n",
    "\n",
    "    def forward(self, x):                                                                              \n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_().to(device)       \n",
    "        out, (hn) = self.gru(x, (h0.detach()))                                                          \n",
    "        out = self.fc(out[:, -1, :])                                                                   \n",
    "       \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU(\n",
      "  (gru): GRU(10, 5, num_layers=3, batch_first=True, dropout=0.2)\n",
      "  (fc): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(data_train.columns)\n",
    "output_dim = 1\n",
    "hidden_dim = 5\n",
    "num_layers = 3\n",
    "dropout = 0.2\n",
    "model = GRU(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers, dropout_prob = dropout).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    train_loss = []\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.view([config.batch_size, -1, input_dim]).to(device), y.to(device)\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, y.unsqueeze(1))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 1000 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "        train_loss.append(loss)   \n",
    "       \n",
    "        \n",
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():                                                    \n",
    "        for X, y in dataloader:\n",
    "            X, y = X.view([config.batch_size, -1, input_dim]).to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            \n",
    "            test_loss += criterion(pred, y.unsqueeze(1)).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "            \n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"val Error: \\n Accuracy: {(100*correct):>0.5f}%, Avg loss: {test_loss:>8f} \\n\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000140  [    0/97812]\n",
      "loss: 0.000123  [64000/97812]\n",
      "val Error: \n",
      " Accuracy: 2.09381%, Avg loss: 0.000004 \n",
      "\n",
      "loss: 0.000140  [    0/97812]\n",
      "loss: 0.000122  [64000/97812]\n",
      "val Error: \n",
      " Accuracy: 2.09381%, Avg loss: 0.000004 \n",
      "\n",
      "loss: 0.000139  [    0/97812]\n",
      "loss: 0.000122  [64000/97812]\n",
      "val Error: \n",
      " Accuracy: 2.09381%, Avg loss: 0.000004 \n",
      "\n",
      "loss: 0.000139  [    0/97812]\n",
      "loss: 0.000121  [64000/97812]\n",
      "val Error: \n",
      " Accuracy: 2.09381%, Avg loss: 0.000004 \n",
      "\n",
      "loss: 0.000139  [    0/97812]\n",
      "loss: 0.000120  [64000/97812]\n",
      "val Error: \n",
      " Accuracy: 2.09381%, Avg loss: 0.000004 \n",
      "\n",
      "loss: 0.000139  [    0/97812]\n",
      "loss: 0.000120  [64000/97812]\n",
      "val Error: \n",
      " Accuracy: 2.09381%, Avg loss: 0.000004 \n",
      "\n",
      "loss: 0.000139  [    0/97812]\n",
      "loss: 0.000120  [64000/97812]\n",
      "val Error: \n",
      " Accuracy: 2.09381%, Avg loss: 0.000004 \n",
      "\n",
      "loss: 0.000139  [    0/97812]\n",
      "loss: 0.000120  [64000/97812]\n",
      "val Error: \n",
      " Accuracy: 2.09381%, Avg loss: 0.000004 \n",
      "\n",
      "loss: 0.000139  [    0/97812]\n",
      "loss: 0.000120  [64000/97812]\n",
      "val Error: \n",
      " Accuracy: 2.09381%, Avg loss: 0.000004 \n",
      "\n",
      "loss: 0.000139  [    0/97812]\n",
      "loss: 0.000120  [64000/97812]\n",
      "val Error: \n",
      " Accuracy: 2.09381%, Avg loss: 0.000004 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, config.epochs + 1):\n",
    "    print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "    train(train_loader, model, criterion, optimizer)\n",
    "    test(val_loader, model)\n",
    "print(\"Done!\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25080"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(torch.Tensor(X_test_ssc), shuffle=False, drop_last=True)\n",
    "with torch.no_grad():\n",
    "    predictions = []\n",
    "    for x in test_loader:\n",
    "        x = x.view([x.shape[0], 1,x.shape[1]]).to(device)\n",
    "        model.eval()\n",
    "        yhat = model(x)\n",
    "        predictions.append(msc.inverse_transform(yhat.cpu().detach().numpy()).reshape(-1))\n",
    "len(predictions)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.601616999865826\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "targets = []\n",
    "with torch.no_grad(): \n",
    "    for X, y in val_loader:\n",
    "        X, y = X.view([config.batch_size, -1, input_dim]).to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        outputs.append(msc.inverse_transform(pred.cpu().detach().numpy()).reshape(-1))\n",
    "        targets.append(msc.inverse_transform(y.cpu().numpy()).reshape(-1))\n",
    "    sMAPE = 0\n",
    "    for i in range(len(outputs)):\n",
    "        smape(targets[i], outputs[i])\n",
    "        sMAPE +=np.mean(smape(targets[i], outputs[i]))\n",
    "    print(sMAPE/len(outputs))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eis_kernel",
   "language": "python",
   "name": "eis_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
